# MultipleLinearRegression
implementation of multiple linear regression framework through Python

In this program, it explores an aspect of machine learning called neaural network. Using a sample dataset that has an two x-variables of real numbers and y-variable of either 0 or 1, the program aims to predict the relationship between the x and y. The data was split into training data and testing data to do so: training set used to find optimal parameters theta0, theta1, and theta2 of the linear equation called the weighted sum, testing set used to compare accuracy between actual output and predicted output. Instead of using the logistic regression class provided by Spyder, the mathematical process was thoroughly outlined hand by hand. This is reflected from the mathematics done in code of the sigmoid function, logarithmic-loss, and the cost function. To further understand the mathematics behind the simple linear regression, refer to the "LogisticRegressionReport" file.

The dataset that was implemented was called "LogisticData". The accuracy of the algorithm for both training and test data came up to be above 85% as seen in the image attached. However, the image showing 100,000 iterations show a greater accuracy of 92.5% train data and 90% test data, compared to the image showing 200,000 iterations with accuracy of 90% train data and 85% test data. This means that for an addition 100,000 iterations, the cost function continues to converge, showing optimization to training data, but showing less optimization to test data as overfitting to training data occurs.
